{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T03:22:37.537309Z",
     "start_time": "2025-03-24T03:22:29.040961Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]\n",
      "执行结果: messages=[HumanMessage(content='你好，你是？', additional_kwargs={}, response_metadata={})]\n",
      "================\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x112a35bb0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x112a54200> root_client=<openai.OpenAI object at 0x107635610> root_async_client=<openai.AsyncOpenAI object at 0x112a35c10> model_name='deepseek-chat' model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.deepseek.com/v1'\n",
      "执行结果: content='您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-V3。如您有任何任何问题，我会尽我所能为您提供帮助。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 7, 'total_tokens': 44, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 7}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4_prod0225', 'finish_reason': 'stop', 'logprobs': None} id='run-8c0db09b-1472-4cd2-8e33-8d8bd62e5480-0' usage_metadata={'input_tokens': 7, 'output_tokens': 37, 'total_tokens': 44}\n",
      "================\n",
      "\n",
      "执行结果: 您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-V3。如您有任何任何问题，我会尽我所能为您提供帮助。\n",
      "================\n",
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-V3。如您有任何任何问题，我会尽我所能为您提供帮助。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from uuid import UUID\n",
    "\n",
    "from langchain_core.outputs import GenerationChunk, ChatGenerationChunk\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (ChatPromptTemplate, PromptTemplate)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import Any, Optional, Union\n",
    "\n",
    "# 1.编排Prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"{query}\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"deepseek-chat\", api_key=os.environ.get(\"DS_KEY\"), base_url=os.environ.get(\"DS_API_BASE\"))\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "\n",
    "class Chain:\n",
    "    steps: list = []\n",
    "\n",
    "    def __init__(self, steps):\n",
    "        self.steps = steps\n",
    "\n",
    "    def invoke(self, input: Any) -> Any:\n",
    "        output: Any = input\n",
    "        for step in self.steps:\n",
    "            output = step.invoke(output)\n",
    "            print(step)\n",
    "            print(\"执行结果:\", output)\n",
    "            print(\"================\")\n",
    "        return output\n",
    "\n",
    "\n",
    "chain = Chain([prompt, llm, parser])\n",
    "print(chain.invoke({\"query\": \"你好，你是？\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc10d8871dac197",
   "metadata": {},
   "source": [
    "## 自定义Chain的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566dd441bcb66d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (ChatPromptTemplate, PromptTemplate)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import Any\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "# 1.编排Prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"{query}\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"deepseek-chat\", api_key=os.environ.get(\"DS_KEY\"), base_url=os.environ.get(\"DS_API_BASE\"))\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "#等价于一下写法\n",
    "# composed_chain_with_pip = (\n",
    "#     RunnableParallel({\"query\": RunnablePassthrough()})\n",
    "#     .pipe(prompt)\n",
    "#     .pipe(llm)\n",
    "#     .pipe(parser)\n",
    "# )\n",
    "\n",
    "print(chain.invoke({\"query\": \"你好，你是?\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61086ead172c0a97",
   "metadata": {},
   "source": [
    "## RunnablePassthrough 传递数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a3887ded112aab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T07:33:57.322320Z",
     "start_time": "2025-03-25T07:33:48.821228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是DeepSeek Chat，由深度求索公司打造的智能AI助手。我可以帮你解答问题、提供建议、聊天交流，还能处理各种文本和文件内容。如果有任何需要，尽管问我吧！😊  \n",
      "\n",
      "有什么可以帮你的呢？\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (ChatPromptTemplate, PromptTemplate)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import Any\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "# 1.编排Prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"{query}\")\n",
    "\n",
    "# 构建大语言模型\n",
    "llm = ChatOpenAI(model=\"deepseek-chat\", api_key=os.environ.get(\"DS_KEY\"), base_url=os.environ.get(\"DS_API_BASE\"))\n",
    "\n",
    "# 创建链\n",
    "#方式一\n",
    "# chain = {\"query\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    "# \n",
    "# content = chain.invoke(\"你好,你是？\")\n",
    "# print(content)\n",
    "\n",
    "#方式二\n",
    "chain = {\"query\": itemgetter(\"query\")} | prompt | llm | StrOutputParser()\n",
    "content = chain.invoke({\"query\": \"你好,你是？\"})\n",
    "print(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb8666a06b0aac",
   "metadata": {},
   "source": [
    "## 传递的数据中添加数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89417c8471ee98e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T07:42:35.230160Z",
     "start_time": "2025-03-25T07:42:27.217919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "执行检索 {'query': '你好我叫什么'}\n",
      "你好，VV！根据我们的对话记录，你的名字是VV，是一名AI应用开发工程师。有什么我可以帮你的吗？ 😊\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (ChatPromptTemplate, PromptTemplate)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import Any\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def retrieval(query: str) -> str:\n",
    "    \"\"\"模拟一个检索器，传入query，输出文本\"\"\"\n",
    "    print(\"执行检索\", query)\n",
    "    return \"我叫VV，是一名AI应用开发工程师\"\n",
    "\n",
    "\n",
    "# 1.编排Prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"请根据用户的提问回他问题，可以参考上下文进行回复\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "用户的问题是:{query}\n",
    "\"\"\")\n",
    "\n",
    "# 构建大语言模型\n",
    "llm = ChatOpenAI(model=\"deepseek-chat\", api_key=os.environ.get(\"DS_KEY\"), base_url=os.environ.get(\"DS_API_BASE\"))\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "        RunnablePassthrough.assign(context=lambda query: retrieval(query)) |\n",
    "        prompt |\n",
    "        llm |\n",
    "        parser\n",
    ")\n",
    "content = chain.invoke({\"query\": \"你好我叫什么\"})\n",
    "\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d5222f33c057e",
   "metadata": {},
   "source": [
    "## 利用回调功能调试链应用-让过程更透明\n",
    "Callback 是 LangChain 提供的回调机制，允许我们在 LLM 应用程序的各个阶段使用 hook (钩 子)。钩子的含义也非常简单，我们把应用程序看成一个一个的处理逻辑，从开始到结束，钩子就是在 事件传送到终点前截获并监控事件的传输。\n",
    "\n",
    "Callback 收集到的信息可以直接输出到控制台，也可以输出到文件，更可以输入到第三方应用，相当于 独立的日志管理系统，通过这些日志就可以分析应用的运行情况，统计异常率，运行的瓶颈模块以便优化。\n",
    "1. CallbackHandler:对每个应用场景比如 Agent 或 Chain 或 Tool 的纪录。\n",
    "2. CallbackManager:对所有 CallbackHandler 的封装和管理，包括了单个场景的 Handle，也包括 运行时整条链路的 Handle。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c641a9911354552",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T08:01:09.781902Z",
     "start_time": "2025-03-25T08:01:01.800874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object RunnableSequence.stream at 0x115d784f0>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableSequence chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableParallel<query> chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnablePassthrough chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ChatPromptTemplate chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StrOutputParser chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (ChatPromptTemplate, PromptTemplate)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import Any\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "\n",
    "# 1.编排Prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"{query}\")\n",
    "\n",
    "# 构建大语言模型\n",
    "llm = ChatOpenAI(model=\"deepseek-chat\", api_key=os.environ.get(\"DS_KEY\"), base_url=os.environ.get(\"DS_API_BASE\"))\n",
    "\n",
    "chain = {\"query\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    "\n",
    "content = chain.stream(\"你好你是？\", config={\n",
    "    \"callbacks\": [StdOutCallbackHandler()]\n",
    "})\n",
    "print(content)\n",
    "\n",
    "for chunk in content:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f155fe676857b846",
   "metadata": {},
   "source": [
    "## 自定义回调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ba19c5597cded4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T08:42:56.593346Z",
     "start_time": "2025-03-25T08:42:49.627466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object RunnableSequence.stream at 0x1117b09a0>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableSequence chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableParallel<query> chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnablePassthrough chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ChatPromptTemplate chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "on_llm_start serialized: {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'], 'kwargs': {'model_name': 'deepseek-chat', 'temperature': 0.7, 'openai_api_key': {'lc': 1, 'type': 'secret', 'id': ['OPENAI_API_KEY']}, 'openai_api_base': 'https://api.deepseek.com/v1', 'max_retries': 2, 'n': 1}, 'name': 'ChatOpenAI'}\n",
      "on_llm_start_ prompts ['Human: 你好你是？']\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StrOutputParser chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.callbacks import  BaseCallbackHandler,StdOutCallbackHandler\n",
    "from uuid import UUID\n",
    "from typing import Dict, Any, List, Optional\n",
    "from typing import Optional,Any,Union\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "class LLMOpsCallbackHandler(BaseCallbackHandler):\n",
    "    \"\"\"自定义LLMOps回调\"\"\"\n",
    "    def on_llm_start(\n",
    "        self,\n",
    "        serialized: dict[str, Any],\n",
    "        prompts: list[str],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[list[str]] = None,\n",
    "        metadata: Optional[dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        print(\"on_llm_start serialized:\",serialized)\n",
    "        print(\"on_llm_start_ prompts\",prompts)\n",
    "\n",
    "    # def on_llm_new_token(\n",
    "    #     self,\n",
    "    #     token: str,\n",
    "    #     *,\n",
    "    #     chunk: Optional[Union[GenerationChunk, ChatGenerationChunk]] = None,\n",
    "    #     run_id: UUID,\n",
    "    #     parent_run_id: Optional[UUID] = None,\n",
    "    #     **kwargs: Any,\n",
    "    # ) -> Any:\n",
    "    #    print(\"on_llm_new_token:\", token)\n",
    "       \n",
    "       \n",
    "# 1.编排Prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"{query}\")\n",
    "\n",
    "# 构建大语言模型\n",
    "llm = ChatOpenAI(model=\"deepseek-chat\", api_key=os.environ.get(\"DS_KEY\"), base_url=os.environ.get(\"DS_API_BASE\"))\n",
    "\n",
    "chain = {\"query\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    "\n",
    "content = chain.stream(\"你好你是？\", config={\n",
    "    \"callbacks\": [StdOutCallbackHandler(),LLMOpsCallbackHandler()]\n",
    "})\n",
    "print(content)\n",
    "\n",
    "for chunk in content:\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
