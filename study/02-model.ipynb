{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-20T08:55:34.869658Z",
     "start_time": "2025-03-20T08:54:32.807103Z"
    }
   },
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (ChatPromptTemplate, PromptTemplate)\n",
    "from datetime import datetime\n",
    "\n",
    "# 1.编排Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是OpenAI开发的聊天机器人，请回答用户的问题，现在的时间是{now}\"), (\"human\", \"{query}\"),\n",
    "]).partial(now=datetime.now())\n",
    "\n",
    "llm = ChatOpenAI(model=\"deepseek-chat\", api_key=os.environ.get(\"DS_KEY\"), base_url=os.environ.get(\"DS_API_BASE\"))\n",
    "\n",
    "prompt_value = prompt.invoke({\"query\": \"现在是几点，请讲一个程序员的冷笑话\"})\n",
    "ai_message = llm.invoke(prompt_value)\n",
    "\n",
    "# 4.提取内容\n",
    "print(\"type:\", ai_message.type)\n",
    "print(\"content:\", ai_message.content)\n",
    "# print(\"response_metadata:\", ai_message.response_metadata)\n",
    "\n",
    "print(\"================================\")\n",
    "\n",
    "##批处理\n",
    "\n",
    "batch_prompt = ChatPromptTemplate.from_template(\"请讲一个关于{subject}的冷笑话\")\n",
    "\n",
    "ai_messages = llm.batch([\n",
    "    batch_prompt.invoke({\"subject\": \"程序员\"}),\n",
    "    batch_prompt.invoke({\"subject\": \"Python\"}),\n",
    "])\n",
    "\n",
    "for ai_message in ai_messages:\n",
    "    print(ai_message.content)\n",
    "    print(\"================================\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: ai\n",
      "content: 现在的时间是2025年3月20日16:54。\n",
      "\n",
      "来一个程序员的冷笑话：\n",
      "\n",
      "为什么程序员总是分不清万圣节和圣诞节？\n",
      "\n",
      "因为 Oct 31 = Dec 25！\n",
      "\n",
      "（解释：在八进制（Octal）中，31等于十进制的25，所以 Oct 31 = Dec 25。）\n",
      "response_metadata: {'token_usage': {'completion_tokens': 68, 'prompt_tokens': 43, 'total_tokens': 111, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 43}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4_prod0225', 'finish_reason': 'stop', 'logprobs': None}\n",
      "================================\n",
      "## 《代码之恋》\n",
      "\n",
      "\"叮咚——\"\n",
      "\n",
      "门铃响起的时候，我正在调试一个棘手的bug。屏幕上的代码像一团乱麻，我揉了揉发酸的太阳穴，起身去开门。\n",
      "\n",
      "门外站着一个穿着格子衬衫的年轻人，他推了推黑框眼镜，露出一个腼腆的笑容：\"你好，我是新搬来的邻居，就住在隔壁。\"\n",
      "\n",
      "我愣了一下。他看起来和我差不多大，手里还端着一盘刚烤好的饼干。浓郁的黄油香气飘进鼻腔，让我想起已经连续吃了三天的泡面。\n",
      "\n",
      "\"啊，你好。\"我接过饼干，\"我是林小夏，程序员。\"\n",
      "\n",
      "\"真巧，我也是。\"他眼睛一亮，\"我叫陈默，在隔壁公司做后端开发。\"\n",
      "\n",
      "就这样，我们认识了。陈默是个典型的程序员，说话时总是带着几分拘谨，但聊起技术来就滔滔不绝。他经常来串门，有时是分享新买的键盘，有时是讨论最新的框架。\n",
      "\n",
      "渐渐地，我发现他看我的眼神有些不一样。每次我调试代码时，他总会偷偷看我，被发现后又慌乱地移开视线。他的耳朵会变得通红，像极了编译错误时的红色警告。\n",
      "\n",
      "那天晚上，我正在写一个递归函数，突然听到隔壁传来一声巨响。我赶紧跑过去，发现陈默倒在地上，脸色苍白。\n",
      "\n",
      "\"你怎么了？\"我扶起他。\n",
      "\n",
      "\"胃...胃病犯了...\"他虚弱地说，\"最近赶项目，又忘记吃饭了...\"\n",
      "\n",
      "我叹了口气，把他扶到沙发上。他的房间和我的一样乱，到处都是外卖盒和空饮料瓶。我打开冰箱，里面只有几罐红牛和一瓶过期的牛奶。\n",
      "\n",
      "\"你这样不行。\"我给他倒了杯温水，\"以后我做饭给你吃吧。\"\n",
      "\n",
      "他愣住了，眼镜片后的眼睛瞪得圆圆的：\"可...可以吗？\"\n",
      "\n",
      "\"当然。\"我笑着说，\"就当是邻居互助。不过你要答应我，按时吃饭，少喝咖啡。\"\n",
      "\n",
      "从那天起，我开始每天给他送饭。他总是一边吃一边给我讲他写的代码，有时候还会给我看他写的诗——是的，这个程序员居然会写诗。\n",
      "\n",
      "\"你看这句：'for(int i=0;i<3;i++){想你}'，用循环表达思念，是不是很有创意？\"他得意地说。\n",
      "\n",
      "我忍俊不禁：\"你这代码编译都过不了。\"\n",
      "\n",
      "\"但我的心意能传达到就行。\"他认真地看着我。\n",
      "\n",
      "那一刻，我感觉自己的心跳漏了一拍。这个呆头呆脑的程序员，什么时候学会说情话了？\n",
      "\n",
      "然而好景不长。那天我照常去送饭，却发现他不在家。打他电话也关机，问了他同事才知道，他因为长期加班，胃病加重住院了。\n",
      "\n",
      "我冲到医院时，他正躺在病床上打点滴。看到我，他勉强挤出一个笑容：\"抱歉，让你担心了。\"\n",
      "\n",
      "\"你这个笨蛋！\"我气得直跺脚，\"不是说好要按时吃饭的吗？\"\n",
      "\n",
      "\"项目太赶了...\"他小声说，\"我想早点完成，就能...就能...\"\n",
      "\n",
      "\"就能什么？\"\n",
      "\n",
      "他深吸一口气，从枕头下摸出一个U盘：\"这是我写的程序，本来想等完成后再给你的。\"\n",
      "\n",
      "我接过U盘，插上电脑。屏幕上跳出一个简单的界面，上面写着：\"林小夏专属天气预报系统\"。\n",
      "\n",
      "\"我知道你总是忘记带伞，\"他轻声说，\"所以写了这个程序。每天早上会自动给你发天气预报，还会根据天气推荐穿搭...\"\n",
      "\n",
      "我的眼眶湿润了。这个傻瓜，为了写这个程序，不知道熬了多少个夜。\n",
      "\n",
      "\"陈默，\"我握住他的手，\"我们在一起吧。\"\n",
      "\n",
      "他愣住了，随即露出一个灿烂的笑容：\"好。\"\n",
      "\n",
      "从那天起，我们开始一起写代码。他负责后端，我负责前端，就像我们的爱情一样，完美契合。有时候我们会因为一个bug争论不休，但最后总能找到最优解。\n",
      "\n",
      "就像他说的：\"我们的爱情就像一段完美的代码，没有bug，只有无限循环的甜蜜。\"\n",
      "\n",
      "当然，这段代码的开头要这样写：\n",
      "\n",
      "while(alive){\n",
      "    love(you);\n",
      "}\n",
      "\n",
      "因为只要活着，我就会一直爱你。\n",
      "当然可以！这是一个关于Python的冷笑话：\n",
      "\n",
      "---\n",
      "\n",
      "有一天，Python列表和元组一起去参加派对。\n",
      "\n",
      "列表玩得很嗨，一直在增增减减，还时不时地插入新朋友。\n",
      "\n",
      "元组却一直站在角落里，一动不动。\n",
      "\n",
      "列表问元组：“你怎么不来一起玩？”\n",
      "\n",
      "元组冷冷地回答：“我不可变。”\n",
      "\n",
      "---\n",
      "\n",
      "希望你喜欢这个冷笑话！😄\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 流式输出",
   "id": "6240a76ab8a710c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T08:59:27.487697Z",
     "start_time": "2025-03-20T08:58:55.362114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (ChatPromptTemplate, PromptTemplate)\n",
    "from datetime import datetime\n",
    "\n",
    "# 1.编排Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是OpenAI开发的聊天机器人，请回答用户的问题，现在的时间是{now}\"), (\"human\", \"{query}\"),\n",
    "]).partial(now=datetime.now())\n",
    "\n",
    "llm = ChatOpenAI(model=\"deepseek-chat\", api_key=os.environ.get(\"DS_KEY\"), base_url=os.environ.get(\"DS_API_BASE\"))\n",
    "\n",
    "chunks =llm.stream(prompt.invoke({\"query\":\"你能简单介绍下llm和llmOps吗\"}))\n",
    "for chunk in chunks:\n",
    "    print(chunk.content,flush=True, end=\"\")"
   ],
   "id": "66ec4ce4bebd9acf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！LLM 和 LLMOps 是当前人工智能领域中的两个重要概念。\n",
      "\n",
      "### 1. **LLM（Large Language Model，大语言模型）**\n",
      "LLM 是指基于大规模数据集训练的自然语言处理模型，能够理解和生成人类语言。这些模型通常基于深度学习架构（如 Transformer），并通过海量文本数据进行预训练，从而具备强大的语言理解和生成能力。典型的例子包括 OpenAI 的 GPT 系列、Google 的 BERT 和 T5 等。\n",
      "\n",
      "LLM 的核心特点包括：\n",
      "- **规模大**：参数量通常在数十亿到数千亿级别。\n",
      "- **通用性强**：可以应用于多种任务，如文本生成、翻译、问答、摘要等。\n",
      "- **上下文理解**：能够根据上下文生成连贯的回复。\n",
      "\n",
      "### 2. **LLMOps（Large Language Model Operations，大语言模型运维）**\n",
      "LLMOps 是指针对大语言模型的开发、部署、监控和优化的全生命周期管理。它类似于传统的 MLOps（机器学习运维），但专门针对 LLM 的特殊需求。\n",
      "\n",
      "LLMOps 的核心任务包括：\n",
      "- **模型训练与微调**：管理大规模训练数据、分布式训练和模型微调。\n",
      "- **部署与扩展**：将 LLM 部署到生产环境，并确保其能够高效处理大量请求。\n",
      "- **监控与优化**：实时监控模型性能，优化推理速度和资源利用率。\n",
      "- **安全与合规**：确保模型输出符合伦理和法律要求，防止滥用或偏见问题。\n",
      "\n",
      "### 两者的关系\n",
      "LLM 是技术核心，而 LLMOps 是确保 LLM 能够在实际应用中高效、稳定运行的关键支撑。随着 LLM 的规模和应用场景的扩展，LLMOps 的重要性也在不断提升。\n",
      "\n",
      "希望这个解释对你有帮助！如果还有其他问题，欢迎随时提问。"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
